# Отчет о потенциальных проблемах производительности и способах их обнаружения/предотвращения в сервисе currency-rate-parser

## Общая информация о проекте

*   **Тип приложения:** Микросервис для парсинга курсов валют.
*   **Основная функциональность:** Приложение периодически инициирует параллельные HTTP GET запросы к 1 поставщику курсов криптовалют валют. Полученные данные (JSON) десериализуются и результат сохраняется в PostgreSQL.
*   **Ключевые технологии:** Java 17, Spring Boot 3, PostgreSQL, **WebClient** (используется реактивный стек для I/O), **Executors Service** (для запланированных задач).
*   **Архитектура:** Монолитная.
*   **Ресурсоёмкие операции:**
    1.  **Сетевые вызовы:** Параллельные HTTP GET запросы к внешнему API (самая частая операция).
    2.  **Обработка данных:** Десериализация и сериализация JSON.
    3.  **Работа с БД:** Массовая вставка/обновление данных.

---

## Анализ по выбранным категориям

Выбраны 3 категории: **Аппаратный уровень (Сетевая пропускная способность)**, **Контекстное переключение (Слишком много потоков)** и **Алгоритмический уровень (Деградация при росте объема)**.

### Категория 1: Аппаратный уровень – Сетевая пропускная способность

#### 1. Как проблема может проявиться
В нашем сервисе основная нагрузка — это ожидание ответа от внешних API. Если внешний сервис внезапно начнет отвечать медленно (например, с задержкой 2 секунды вместо 200 мс), или введет жёсткое ограничение по частоте запросов (Rate Limiting), это немедленно скажется на общей производительности.

#### 2. Обоснование опасений
**Опасаюсь.** Поскольку приложение реактивное (WebClient), оно хорошо справляется с неблокирующим I/O. Однако, если мы превысим лимит соединений, установленный на стороне ОС или самого клиента (например, если настроен слишком большой пул соединений), мы получим ошибки, связанные с сетью, а не с CPU. Если же мы будем слишком часто стучаться в одно API, рискуем получить блокировку.

#### 3. Обнаружение и предотвращение

**Обнаружение:**
*   **Инструменты:** **Micrometer/Prometheus** и **Grafana**.
*   **Метрики:** Мониторинг времени ответа каждого внешнего HTTP-клиента (используя теги в Micrometer). Необходимо отслеживать `http_client_requests_seconds_max` (P99) и количество ошибок HTTP 429.
*   **Визуализация:** На дашборде Grafana строится график, где отображаются задержки по каждому запросу.

**Предотвращение:**
1.  **Конфигурация WebClient:** Настройка явных, разумных таймаутов (например, 5 секунд на весь запрос).
2.  **Ограничение пула соединений:** Убедиться, что пул соединений WebClient не является чрезмерно большим, чтобы избежать исчерпания ресурсов сокета на стороне приложения.
3.  **Client-Side Rate Limiting:** Использование библиотеки типа Bucket4j для мягкого ограничения частоты запросов к **конкретному** внешнему API, который известен своей нестабильностью.

---

### Категория 2: Контекстное переключение – Слишком много потоков

#### 1. Как проблема может проявиться
Хотя Spring Boot и WebClient используют реактивность, основной цикл сбора данных запускается по расписанию (например, с помощью `@Scheduled` или `Executors.newSingleThreadScheduledExecutor()`). Если обработка данных (десериализация) после получения ответа занимает слишком много времени, и мы начинаем накапливать "отложенные" задачи, это может привести к неэффективному использованию потоков.

#### 2. Обоснование опасений
**Опасаюсь, но с оговоркой.** Поскольку мы используем WebClient, I/O-связанные операции не блокируют потоки CPU. Проблема возникнет, если мы введем в обработку (например, при записи в лог, если он очень большой, или при расчетах) блокирующие операции, и вызовем их в потоках, управляемых неоптимально. **Если мы не используем явные блокирующие пулы для обработки, риск невелик.** Но если мы неправильно настроим обработку ошибок или логирование, можем породить множество короткоживущих потоков, увеличивая накладные расходы на контекстное переключение.

#### 3. Обнаружение и предотвращение

**Обнаружение:**
*   **Инструменты:** **VisualVM** (для анализа активности потоков) или **JMX/Micrometer** (для счетчика `system.cpu.context_switches`).
*   **Диагностика:** Если система показывает высокий процент использования CPU, но при этом очень низкую пропускную способность (по количеству успешно обработанных запросов), это может указывать на избыточное переключение контекста. В VisualVM можно увидеть большое количество потоков, находящихся в состоянии `RUNNABLE` или `WAITING` по коротким интервалам.

**Предотвращение:**
1.  **Избегать неконтролируемых пулов:** Никогда не использовать `Executors.newCachedThreadPool()` для задач, которые могут выполняться долго.
2.  **Использовать управляемый пул:** Для запланированных задач, которые должны выполняться последовательно, использовать фиксированный пул потоков (например, `Executors.newFixedThreadPool(N)`) или стандартный пул Spring Boot. Если 8 источников требуют обработки, достаточно пула, размер которого близок к числу ядер CPU, так как CPU-bound задачи должны быть ограничены.
3.  **Реактивная обработка:** Убедиться, что вся десериализация и нормализация также обрабатывается на реактивных цепочках (например, `.map()` или `.flatMap()`), а не принудительно перебрасывается на блокирующие потоки (например, `.subscribeOn(Schedulers.boundedElastic())` только если это абсолютно необходимо).

---

### Категория 3: Алгоритмический уровень

#### 1. Какой алгоритм используется для обработки данных?
Основной алгоритм — это **трансформация данных (Mapping)**. Для каждого входящего JSON ответа применяется фиксированный набор правил: извлечение пары (Валюта, Курс) и умножение/деление на коэффициент для приведения к базовой валюте (например, USD).

#### 2. Может ли он деградировать при росте объёма данных?
**Незначительно.** Поскольку объём данных для одного цикла обновления (один набор курсов от источника) относительно мал (несколько килобайт JSON), деградация по времени будет линейной и очень слабой. Десериализация JSON (которая обычно имеет сложность $O(N)$, где $N$ — размер полезной нагрузки) не вызовет проблем, пока размер ответа не достигнет мегабайтов.

#### 3. Есть ли более эффективная альтернатива?
Поскольку мы имеем дело с четко структурированными JSON и фиксированными правилами трансформации, **нет более эффективной общей альтернативы**, чем использование быстрых парсеров (например, Jackson или Gson). Мы уже используем эффективный подход.

#### 4. Обоснование опасений
**Не опасаюсь.** Алгоритмический уровень не является узким местом. Основная "тяжесть" — это I/O (сетевые задержки), а не вычисления. Мы не выполняем сложные сортировки, графовые обходы или рекурсивные вычисления, которые могли бы деградировать по $O(N^2)$ или $O(2^N)$.

#### 5. Обнаружение и предотвращение
*   **Обнаружение:** Если бы мы обнаружили, что CPU загружен на 90% *только* во время обработки, а не во время ожидания сети, мы бы использовали **VisualVM (Profiler)** для точного определения, какая именно строка кода в методе парсинга занимает больше всего времени.
*   **Предотвращение:** Если бы объемы выросли, можно было бы рассмотреть переход от чистой Java-десериализации к более низкоуровневым, оптимизированным для скорости парсерам (например, StAX для XML, если бы мы обрабатывали огромные документы, или специальные библиотеки для парсинга JSON в стиле C/C++). В текущем сценарии это избыточно.

---

## Вывод

Приложение, будучи реактивным парсером, в первую очередь подвержено проблемам, связанным с **аппаратным уровнем (сетевые задержки)** и **управлением потоками (контекстное переключение)**, а не с алгоритмической сложностью. Наибольший риск представляет непредсказуемость внешних API, которая может привести к исчерпанию ресурсов ожидания. Для минимизации рисков необходимо усилить мониторинг внешних вызовов через Micrometer и внедрить строгие таймауты. Алгоритмическая часть кажется достаточно эффективной для текущих объемов данных.
